{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andentze/FaceColab_Unofficial/blob/main/FaceColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7-0WoBC71P8"
      },
      "source": [
        "# Faceswap Notebook\n",
        " \n",
        "Welcome to the Faceswap *not official* notebook. Ever had a problem with your PC/laptop not being good enough for Faceswap? This notebook will help you out with **everything** regarding Faceswap.\n",
        " \n",
        " \n",
        "Feel free to set up the environment as you like. I, personally, prefer my dataset and the model being on the Google Drive directly, or something like this:\n",
        " \n",
        "> \"/content/drive/My Drive/colab/faceswap/model\n",
        " \n",
        "> \"/content/drive/My Drive/colab/faceswap/faces/A\n",
        " \n",
        "> /content/drive/My Drive/colab/faceswap/faces/B\n",
        " \n",
        "> /content/drive/My Drive/colab/faceswap/config\n",
        " \n",
        "and so on.\n",
        " \n",
        "You can choose to either use the GUI version of Faceswap(*which can take some time to set up*) or the CLI version of Faceswap that is present here.\n",
        " \n",
        "You will also receive 4 kinds of GPUs: P4, T4, K80 or P100(*different kinds of GPU's in Colab Pro which are proven to be faster*). Also, you get 12 hours of notebook usage until you get disconnected(24 hours in Colab Pro). You *might* get frequent disconnects.\n",
        " \n",
        "And before you start using this notebook, clone it to your Google Drive. (File -> Save a copy in Drive)\n",
        "\n",
        "**I TAKE NO CREDIT FOR ANY REPOSITORIES, NOR SOFTWARE USED IN THIS NOTEBOOK. ANYTHING USED HERE IS NOT MINE.**\n",
        "\n",
        "*If you wish to support me by buying me a donut, feel free to [donate](https://www.donationalerts.com/r/andentze).* You *may* get early access to the notebook updates, which I'm not really sure is needed. But at the end of the day, it's one way to support me."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7TctjDRl8d3N"
      },
      "outputs": [],
      "source": [
        "#@title Check the current GPU\n",
        "#@markdown Right here you can check what kind of GPU you have available right now. Run this code to output the GPU used.\n",
        "#@markdown If it errors out, make sure your runtime type is set to \"GPU\".\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "btFh5tBGExWQ"
      },
      "outputs": [],
      "source": [
        "#@title Keep-Alive Script\n",
        "#@markdown You have to activate this to automatically reconnect if Colab disconnects you. Run this code, to activate the \"Keep-Alive\" script.\n",
        "#@markdown And just to make sure, open the console using Ctrl+Shift+I, and paste the code below. This will work efficently for both CLI and DE.\n",
        " \n",
        "import IPython\n",
        "from google.colab import output\n",
        " \n",
        "display(IPython.display.Javascript('''\n",
        "function ClickConnect() {\n",
        "  console.log('Working')\n",
        "  document\n",
        "    .querySelector('#top-toolbar > colab-connect-button')\n",
        "    .shadowRoot.querySelector('#connect')\n",
        "    .click()\n",
        "}\n",
        " \n",
        "setInterval(ClickConnect, 60000)\n",
        "'''))\n",
        " \n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnAN0NQAGe49"
      },
      "source": [
        "> function ClickConnect() {\n",
        "\n",
        ">  console.log('Working')\n",
        "\n",
        ">  document\n",
        "\n",
        ">    .querySelector('#top-toolbar > colab-connect-button')\n",
        "\n",
        ">    .shadowRoot.querySelector('#connect')\n",
        "\n",
        ">    .click()\n",
        "}\n",
        "\n",
        ">    setInterval(ClickConnect, 60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVcGpeieHXHb"
      },
      "source": [
        "# Setting up the CLI\n",
        "\n",
        "Not a fan of the GUI or it simply doesn't work? Look no furher. From this point you will install Faceswap directly to Colab without the need of the DE.\n",
        "\n",
        "It was set up so even a toddler could figure out how it works."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Faceswap and base dependencies\n",
        "\n",
        "#@markdown Since Faceswap got official support of Tensorflow 2.8, running this will be enough for main functionality of Faceswap.\n",
        "\n",
        "#@markdown This will take around a minute.\n",
        "\n",
        "#@markdown If you wish to copy your config files from your Drive, feel free to fill these in.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train = \"train.ini dir(/content/dir/train.ini)\" #@param {type:\"string\"}\n",
        "extract = \"extract.ini dir(/content/dir/extract.ini)\" #@param {type:\"string\"}\n",
        "convert = \"convert.ini dir(/content/dir/convert.ini)\" #@param {type:\"string\"}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/deepfakes/faceswap\n",
        "clear_output()\n",
        "\n",
        "!cp \"{train}\" faceswap/config/\n",
        "!cp \"{extract}\" faceswap/config/\n",
        "!cp \"{convert}\" faceswap/config/\n",
        "clear_output()\n",
        "\n",
        "%env FACESWAP_BACKEND = \"nvidia\"\n",
        "!pip install -r \"/content/faceswap/requirements/_requirements_base.txt\"\n",
        "clear_output()\n",
        "\n",
        "print(\"You are good to go.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GRaa4GUuFIsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvi8sfssLKR8"
      },
      "source": [
        "And with that, you're good to go! You can go ahead, and use Faceswap at your own will!(*that is, until you hit a 12 hour mark.*)\n",
        "\n",
        "**It appears Colab doesn't like long-terms calculations. So it will disconnect you at the most random times. BE AWARE OF THAT.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgIDaoDPemKr"
      },
      "source": [
        "# Workflow\n",
        " \n",
        "Welcome to the Faceswap environment. Your first step is to extract the faces from your footage. After which you're going to have to fix your dataset. While PC/laptop users can fix that locally, mobile users will have to use the DE to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zta3jdNf7Wlf"
      },
      "outputs": [],
      "source": [
        "#@title Extraction\n",
        "#@markdown Extraction is the first step for dataset creation. You **must** have good data in order for training to work better. Use this code snippet to extract your dataset.\n",
        " \n",
        "#set variables start\n",
        " \n",
        "input_dir = \"/content/dir/to/video.mp4\" #@param {type:\"string\"}\n",
        "output_dir = \"/content/dir/to/faces/folder\" #@param {type:\"string\"}\n",
        "detector = \"s3fd\" #@param [\"cv2-dnn\", \"mtcnn\", \"s3fd\"]\n",
        "alignment = \"fan\" #@param [\"cv2dnn\", \"fan\"]\n",
        "masker = \"bisenet-fp\" #@param [\"bisenet-fp\", \"unet-dfl\", \"vgg-clear\", \"vgg-obstructed\"]\n",
        "al_normalization = \"hist\" #@param [\"clahe\", \"hist\", \"mean\"]\n",
        "refeed = 4 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "size = 512 #@param {type:\"slider\", min:256, max:2048, step:64}\n",
        "extract_every_n = 1 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "\n",
        "#set variables end\n",
        "!python3 '{path}'faceswap.py extract \\\n",
        "-i '{input_dir}' \\\n",
        "-o '{output_dir}' \\\n",
        "-D '{detector}' \\\n",
        "-A '{alignment}' \\\n",
        "-nm '{al_normalization}' \\\n",
        "-M '{masker}' \\\n",
        "-rf '{refeed}' \\\n",
        "-min 20 -l 0.4 \\\n",
        "-sz '{size}' \\\n",
        "-een '{extract_every_n}' \\\n",
        "-si 0 -ssf -L INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "twHA2JGjzPXB"
      },
      "outputs": [],
      "source": [
        "#@title Extraction with saving faces\n",
        "#@markdown Extraction is the first step for dataset creation. You **must** have good data in order for training to work better. Use this code snippet to extract your dataset.\n",
        "\n",
        "#@markdown The script above extracts each face and does not save faces to the directory. Use this code to actually save faces and tinker around with them.\n",
        "\n",
        "#set variables start\n",
        "\n",
        "!python3 '{path}'faceswap.py extract \\\n",
        "-i '{input_dir}' \\\n",
        "-o '{output_dir}' \\\n",
        "-D '{detector}' \\\n",
        "-A '{alignment}' \\\n",
        "-M '{masker}' \\\n",
        "-nm '{al_normalization}' \\\n",
        "-rf '{refeed}' \\\n",
        "-min 20 -l 0.4 \\\n",
        "-sz '{size}' \\\n",
        "-een '{extract_every_n}' \\\n",
        "-si 0 -L INFO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip the dataset\n",
        "#@markdown If you have the dataset ready to use on your PC and it's quite massive, it's *much* better to pack it to the .zip file and upload it to the Drive.\n",
        "\n",
        "zip_directory = \"/content/dir/to/file.zip\" #@param {type:\"string\"}\n",
        "output_directory = \"/content/dir/to/faces/A or B\" #@param {type:\"string\"}\n",
        "#@markdown Output directory depends on which side of the face are you unpacking. Do note that it may take a while to unpack and may heavily fill your Drive storage.\n",
        "\n",
        "#@markdown The original .zip file will be deleted right after the unpacking is finished.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!unzip '{zip_directory}' -d '{output_directory}'\n",
        "!rm '{zip_directory}'\n",
        "clear_output()\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P7kIctLDr40I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6D42AWnZUc6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "#@markdown Now, you have your dataset at tip-top shape! All you have to do is start training now! But wait. Before you actually start, make sure your configuration was set right.\n",
        " \n",
        "#@markdown Made sure? Then get to training by setting up the variables first.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#set variables start\n",
        "input_a = \"/content/dir/to/faces/A\" #@param {type:\"string\"}\n",
        "input_b = \"/content/dir/to/faces/B\" #@param {type:\"string\"}\n",
        "num_iterations = 100000 #@param {type:\"slider\", min:100000, max:3000000, step:25000}\n",
        "save_every = 360 #@param {type:\"slider\", min:360, max:1800, step:360}\n",
        "save_model_every = 25000 #@param {type:\"slider\", min:25000, max:100000, step:25000}\n",
        "batch_num = 16 #@param {type:\"slider\", min:4, max:72, step:4}\n",
        "trainer_type = \"dfaker\" #@param [\"lightweight\", \"original\", \"iae\", \"dfaker\", \"dlight\", \"unbalanced\", \"dfl-h128\", \"villain\", \"phaze-a\"] \n",
        "model_dir = \"/content/dir/to/model\" #@param {type:\"string\"}\n",
        "timelapse_dir = \"/content/dir/to/timelapse\" #@param {type:\"string\"}\n",
        "\n",
        "#set variables end\n",
        "\n",
        "print(\"Please wait, while it pre-loads the A dataset.\")\n",
        "print(\"This may take a while depending on how many faces you have.\")\n",
        "print(\"Pre-loading is needed to load EVERY image in the directory for Faceswap.\")\n",
        "print(\"If the dataset is not pre-loaded, some images may not load into the model.\")\n",
        "!dir '{input_a}'\n",
        "clear_output()\n",
        "print(\"Please wait, while it pre-loads the B dataset.\")\n",
        "print(\"This may take a while depending on how many faces you have.\")\n",
        "print(\"Pre-loading is needed to load EVERY image in the directory for Faceswap.\")\n",
        "print(\"If the dataset is not pre-loaded, some images may not load into the model.\")\n",
        "!dir '{input_b}'\n",
        "clear_output()\n",
        "\n",
        "   #fit training args: -nw -nf\n",
        " \n",
        "!python3 '{path}'/faceswap.py train \\\n",
        "  -A '{input_a}' \\\n",
        "  -B '{input_b}' \\\n",
        "  -m '{model_dir}' \\\n",
        "  -t '{trainer_type}' \\\n",
        "  -bs '{batch_num}' \\\n",
        "  -it '{num_iterations}' \\\n",
        "  -s '{save_every}' \\\n",
        "  -ss '{save_model_every}' \\\n",
        "  -tia '{input_a}' \\\n",
        "  -tib '{input_b}' \\\n",
        "  -to '{timelapse_dir}' \\\n",
        "  -w "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YnHtwcncTuOd"
      },
      "outputs": [],
      "source": [
        "#@title Training with No Warp\n",
        "#@markdown Disabling the warp can let you achieve extra sharpness. Start this training sequence if you think your model has trained enough(*judge by the previews*).\n",
        "#@markdown Your variables are saved from the training session above. If not, start your normal training sequence first, then terminate it.\n",
        "\n",
        "\n",
        "!python3 '{path}'/faceswap.py train \\\n",
        "  -A '{input_a}' \\\n",
        "  -B '{input_b}' \\\n",
        "  -m '{model_dir}' \\\n",
        "  -t '{trainer_type}' \\\n",
        "  -bs '{batch_num}' \\\n",
        "  -it '{num_iterations}' \\\n",
        "  -s '{save_every}' \\\n",
        "  -ss '{save_model_every}' \\\n",
        "  -tia '{input_a}' \\\n",
        "  -tib '{input_b}' \\\n",
        "  -to '{timelapse_dir}' \\\n",
        "  -w \\\n",
        "  -nw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ORdq3Tx1lgAu"
      },
      "outputs": [],
      "source": [
        "#@title Convert\n",
        "#@markdown After your model is trained enough, you can convert your final result. Fill the variables and run the code yet another time.\n",
        "\n",
        "#variables set\n",
        "input_video = \"/content/dir/videoA.mp4\" #@param {type:\"string\"}\n",
        "output_dir = \"/content/dir/output\" #@param {type:\"string\"}\n",
        "alignments = \"/content/dir/alignments.fsa\" #@param {type:\"string\"}\n",
        "model_dir = \"/content/dir/your_model\" #@param {type:\"string\"}\n",
        "color_adj = \"\" #@param [\"\", \"avg-color\", \"color-transfer\", \"manual-balance\", \"match-hist\", \"seamless-clone\"]\n",
        "mask = \"\" #@param [\"\", \"components\", \"extended\", \"unet-dfl\", \"vgg-clear\", \"vgg-obstructed\", \"predicted\", \"bisenet-fp_face\", \"bisenet-fp_head\"]\n",
        "writer = \"ffmpeg\" #@param [\"ffmpeg\", \"gif\", \"opencv\", \"pillow\"]\n",
        "output_scale = 100 #@param {type:\"slider\", min:25, max:400, step:5}\n",
        "#@markdown \"Predicted\" mask type is used only if you trained your own mask using \"Learn Mask\". If you're not sure, use \"Components\" or \"Extended\" as they are used by default.\n",
        "#variables end\n",
        "\n",
        "!python3 faceswap/faceswap.py convert \\\n",
        "-i '{input_video}' \\\n",
        "-o '{output_dir}' \\\n",
        "-al '{alignments}' \\\n",
        "-m '{model_dir}' \\\n",
        "-c '{color_adj}' \\\n",
        "-M '{mask}' \\\n",
        "-w '{writer}' \\\n",
        "-osc '{output_scale}' -l 0.4 -j 0 -L INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PYMlgKBSw8iZ"
      },
      "outputs": [],
      "source": [
        "#@title Convert with Swap Model\n",
        "#@markdown Noticed that you trained the model the other way around? Do not worry. Run this to convert it the other way around.\n",
        "\n",
        "#@markdown The variables should stay the same as from the code above.\n",
        "\n",
        "!python3 faceswap/faceswap.py convert \\\n",
        "-i '{input_video}' \\\n",
        "-o '{output_dir}' \\\n",
        "-al '{alignments}' \\\n",
        "-m '{model_dir}' \\\n",
        "-c '{color_adj}' \\\n",
        "-M '{mask}aa' \\\n",
        "-w '{writer}' \\\n",
        "-osc '{output_scale}' -s -l 0.4 -j 0 -L INFO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqe2bTXRKjGC"
      },
      "source": [
        "# Various Tools\n",
        "\n",
        "*Use if necessary.*\n",
        "\n",
        "Faceswap provides a couple of handy tools for you to make your dataset managment easier. Here you can do whatever you want(*limited to the \"Manual\" tool as it requires a desktop environment*)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faceswap Tools\n",
        "\n",
        "These are the most handy tools to use for managing the dataset using Faceswap."
      ],
      "metadata": {
        "id": "JkG_dSBnvcau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "83ydXHCnqjDR"
      },
      "outputs": [],
      "source": [
        "#@title Alignments\n",
        "#@markdown This tool allows you to perform various actions to the alignments file. It is usually stored next to the video source file.\n",
        "#@markdown You would only need \"Remove Faces\" job for most of the time.\n",
        "#@markdown If you wish to use any other tool, proceed to the guides to find out how to use some of them.\n",
        "#set variables\n",
        "job = \"remove-faces\" #@param [\"draw\", \"extract\", \"missing-alignments\", \"missing-frames\", \"multi-faces\", \"no-faces\", \"remove-faces\", \"rename\", \"sort\"]\n",
        "alignments = \"/content/dir/alignments.fsa\" #@param {type:\"string\"}\n",
        "faces = \"/content/dir/A or B\" #@param {type:\"string\"}\n",
        "drive_install = False #@param {type:\"boolean\"}\n",
        "if drive_install:\n",
        "  path = \"/content/drive/My Drive/faceswap/\"\n",
        "  print(\"The installation is on Google Drive. Using Drive directory.\")\n",
        "if not drive_install:\n",
        "  path = \"/content/faceswap/\"\n",
        "  print(\"The installation is local. Using local directory.\")\n",
        "#end variables\n",
        "!python3 faceswap\\tools.py alignments \\\n",
        "-j '{job}' \\\n",
        "-o console \\\n",
        "-a '{alignments}' \\\n",
        "-fc '{faces}' \\\n",
        "-een 1 -sz 512 -L INFO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td8VqXsuq8S4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title FFmpeg\n",
        "#@markdown Generate videos for timelapse(*usually this tool is required for that*). **Strongly** recommended to use BRU first to rename each timestamp to start from 000000.jpeg.\n",
        "\n",
        "#set variables\n",
        "input = \"your/timelapse/dir/here\" #@param {type:\"string\"}\n",
        "output = \"your/video/output/here/example.mp4\" #@param {type:\"string\"}\n",
        "fps = 5 #@param {type:\"slider\", min:1, max:60}\n",
        "\n",
        "#end variables\n",
        "!python3 faceswap\\tools.py effmpeg \\\n",
        "-a gen-vid \\\n",
        "-i input \\\n",
        "-o output \\\n",
        "-fps fps \\\n",
        "-ef .png \\\n",
        "-s 00:00:00 \\\n",
        "-e 00:00:00 \\\n",
        "-d 00:00:00 -sc 1920x1080 -L INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YjpMdDFktO-m"
      },
      "outputs": [],
      "source": [
        "#@title Sort\n",
        "\n",
        "#@markdown This is the Sort tool. It helps you with cleaning your dataset more efficiently.\n",
        "\n",
        "#@markdown The sorting may require **a lot** of RAM depending on your dataset quantity. The bigger your dataset is, the more RAM you may need.\n",
        "\n",
        "#@markdown The formula for calculating the ammount of RAM is: *(nÂ² * 24) / 1.8* where *n* is the number of images.\n",
        "#@markdown The number you'll get is in bytes, so divide it by 1024 for megabytes, and by 1024 again to get gigabytes.\n",
        "\n",
        "#@markdown If the sorting fails(*i.e. the OOM issue*), divide the dataset in some small parts and sort each one of them.\n",
        "\n",
        "#@markdown Please note, that there are only those jobs, that **I** think are useful.\n",
        "input = \"/content/drive/MyDrive/colab_files/faceswap/faces/B\" #@param{type:\"string\"}\n",
        "job = \"face-yaw\" #@param [\"face\", \"blur\", \"hist\", \"face-yaw\"]\n",
        "\n",
        "!python3 faceswap/tools.py sort \\\n",
        "-i '{input}' \\\n",
        "-s '{job}' \\\n",
        "-t -1.0 -fp rename -g hist -b 5 -lf sort_log.json -L INFO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "FaceColab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}